{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t6YQPHhXjJg_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbbdf05c-9915-4388-b6d9-714e20ca764f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "   Unnamed: 0  carat      cut color clarity  depth  table  price     x     y  \\\n",
            "0           1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98   \n",
            "1           2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84   \n",
            "\n",
            "      z  \n",
            "0  2.43  \n",
            "1  2.31  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 53940 entries, 0 to 53939\n",
            "Data columns (total 10 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   carat    53940 non-null  float64\n",
            " 1   cut      53940 non-null  object \n",
            " 2   color    53940 non-null  object \n",
            " 3   clarity  53940 non-null  object \n",
            " 4   depth    53940 non-null  float64\n",
            " 5   table    53940 non-null  float64\n",
            " 6   price    53940 non-null  int64  \n",
            " 7   x        53940 non-null  float64\n",
            " 8   y        53940 non-null  float64\n",
            " 9   z        53940 non-null  float64\n",
            "dtypes: float64(6), int64(1), object(3)\n",
            "memory usage: 4.1+ MB\n",
            "carat\n",
            "0.30    2604\n",
            "0.31    2249\n",
            "1.01    2242\n",
            "0.70    1981\n",
            "0.32    1840\n",
            "        ... \n",
            "3.02       1\n",
            "3.65       1\n",
            "3.50       1\n",
            "3.22       1\n",
            "3.11       1\n",
            "Name: count, Length: 273, dtype: int64\n",
            "cut\n",
            "Ideal        21551\n",
            "Premium      13791\n",
            "Very Good    12082\n",
            "Good          4906\n",
            "Fair          1610\n",
            "Name: count, dtype: int64\n",
            "color\n",
            "G    11292\n",
            "E     9797\n",
            "F     9542\n",
            "H     8304\n",
            "D     6775\n",
            "I     5422\n",
            "J     2808\n",
            "Name: count, dtype: int64\n",
            "clarity\n",
            "SI1     13065\n",
            "VS2     12258\n",
            "SI2      9194\n",
            "VS1      8171\n",
            "VVS2     5066\n",
            "VVS1     3655\n",
            "IF       1790\n",
            "I1        741\n",
            "Name: count, dtype: int64\n",
            "depth\n",
            "62.0    2239\n",
            "61.9    2163\n",
            "61.8    2077\n",
            "62.2    2039\n",
            "62.1    2020\n",
            "        ... \n",
            "71.3       1\n",
            "44.0       1\n",
            "53.0       1\n",
            "53.1       1\n",
            "54.7       1\n",
            "Name: count, Length: 184, dtype: int64\n",
            "table\n",
            "56.0    9881\n",
            "57.0    9724\n",
            "58.0    8369\n",
            "59.0    6572\n",
            "55.0    6268\n",
            "        ... \n",
            "51.6       1\n",
            "63.5       1\n",
            "43.0       1\n",
            "62.4       1\n",
            "61.6       1\n",
            "Name: count, Length: 127, dtype: int64\n",
            "price\n",
            "605      132\n",
            "802      127\n",
            "625      126\n",
            "828      125\n",
            "776      124\n",
            "        ... \n",
            "8816       1\n",
            "14704      1\n",
            "14699      1\n",
            "14698      1\n",
            "9793       1\n",
            "Name: count, Length: 11602, dtype: int64\n",
            "x\n",
            "4.37     448\n",
            "4.34     437\n",
            "4.33     429\n",
            "4.38     428\n",
            "4.32     425\n",
            "        ... \n",
            "10.74      1\n",
            "9.36       1\n",
            "8.89       1\n",
            "10.23      1\n",
            "10.00      1\n",
            "Name: count, Length: 554, dtype: int64\n",
            "y\n",
            "4.34     437\n",
            "4.37     435\n",
            "4.35     425\n",
            "4.33     421\n",
            "4.32     414\n",
            "        ... \n",
            "8.89       1\n",
            "10.16      1\n",
            "9.46       1\n",
            "9.63       1\n",
            "31.80      1\n",
            "Name: count, Length: 552, dtype: int64\n",
            "z\n",
            "2.70     767\n",
            "2.69     748\n",
            "2.71     738\n",
            "2.68     730\n",
            "2.72     697\n",
            "        ... \n",
            "5.79       1\n",
            "5.72       1\n",
            "5.91       1\n",
            "5.61       1\n",
            "31.80      1\n",
            "Name: count, Length: 375, dtype: int64\n",
            "X_train size : (37758, 9)\n",
            "X_test size : (16182, 9)\n",
            "y_train size : (37758,)\n",
            "y_test size : (16182,)\n",
            "R^2 score for Train using sklearn: 0.8838780842365068\n",
            "R^2 score for Test using sklearn: 0.8878187588744918\n",
            "\n",
            "Mean Absolute Error for Train: 872.0510348697445\n",
            "Mean Absolute Error for Test: 853.7910819184326\n",
            "\n",
            "Mean Absolute Percentage Error for Train: 1.5814641367500504\n",
            "Mean Absolute Percentage Error for Test: 1.4816394864517115\n",
            "R^2 score for Train using mlp: 0.93076004004692\n",
            "R^2 score for Test using mlp: 0.9328537040781504\n",
            "\n",
            "Mean Absolute Error for Train: 587.7431213833947\n",
            "Mean Absolute Error for Test: 571.8317102687195\n",
            "\n",
            "Mean Absolute Percentage Error for Train: 0.1949282408440266\n",
            "Mean Absolute Percentage Error for Test: 0.17473531407542156\n"
          ]
        }
      ],
      "source": [
        "### Context\n",
        "#This classic dataset contains the prices and other attributes of almost 54,000 diamonds.\n",
        "\n",
        "### Content\n",
        "'''\n",
        "**price** price in US dollars (\\\\$326--\\\\$18,823)\n",
        "\n",
        "**carat** weight of the diamond (0.2--5.01)\n",
        "\n",
        "**cut** quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n",
        "\n",
        "**color** diamond colour, from J (worst) to D (best)\n",
        "\n",
        "**clarity** a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n",
        "\n",
        "**x** length in mm (0--10.74)\n",
        "\n",
        "**y** width in mm (0--58.9)\n",
        "\n",
        "**z** depth in mm (0--31.8)\n",
        "\n",
        "**depth** total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43--79)\n",
        "\n",
        "**table** width of top of diamond relative to widest point (43--95)\n",
        "'''\n",
        "\n",
        "# importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# loding the csv file as pandas dataframe\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 데이터 디렉토리 경로 설정\n",
        "data_dir = '/content/diamonds.csv'\n",
        "\n",
        "diamonds = pd.read_csv(data_dir)\n",
        "# Looking at the loaded data\n",
        "print(diamonds.head(2))\n",
        "\n",
        "# dropping the first column\n",
        "diamonds = diamonds.drop(diamonds.columns[0], axis=1)\n",
        "\n",
        "# code to directly delete first column, while loding the data from csv file\n",
        "# diamonds = pd.read_csv('G:\\My Research\\CSV Files\\diamonds.csv').iloc[:,1:]\n",
        "diamonds.head()\n",
        "# checking the datatypes and null values in the data\n",
        "diamonds.info()\n",
        "#**From the above, we can see that there are no null values in our dataset.**\n",
        "# if there are null values presents in the data, then we can use imputer for filling those null values\n",
        "# from sklearn.preprocessing import Imputer\n",
        "# checking for the unique values and their total counts in the dataset,\n",
        "# to get an insight about categorical and numerical variables in the dataset\n",
        "for i in diamonds:\n",
        "    print(diamonds[i].value_counts())\n",
        "\n",
        "# defining the variables into Categorical and Numerical\n",
        "#**Categorical Variables :** cut, color, clarity\n",
        "#*Numerical Variables :** carat, depth, table, price, x, y, z\n",
        "# defining the variables into Dependent and Independent\n",
        "#**Dependent Variable :** price\n",
        "#**Independent Variable :** carat, cut, color, clarity, depth, table, x, y, z\n",
        "# Now we will see the distribution of variables\n",
        "d_cat = diamonds[['cut', 'color', 'clarity']]\n",
        "d_num = diamonds[['carat', 'depth', 'table', 'price', 'x', 'y', 'z']]\n",
        "d_num.describe()\n",
        "#From the above graph we can see that there are many outliers present in our data, thus outlier treatment is necessary,\n",
        "#but here, the target variable is Price and as we are predicting price of diamonds, then extreme values are possible, depending about the dimentions of the diamonds.\n",
        "diamonds.price.describe()\n",
        "\n",
        "# encoding categorical variables using LabelEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "diamonds['cut'] = le.fit_transform(diamonds['cut'])\n",
        "diamonds['color'] = le.fit_transform(diamonds['color'])\n",
        "diamonds['clarity'] = le.fit_transform(diamonds['clarity'])\n",
        "diamonds.dtypes\n",
        "#**Splitting the data into train and test**\n",
        "# Splitting the data into dependent and independent variables\n",
        "X=diamonds.drop('price', axis=1)\n",
        "y=diamonds['price']\n",
        "\n",
        "# Splitting into test and train data (70:30)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.30, random_state = 1)\n",
        "print('X_train size :',X_train.shape)\n",
        "print('X_test size :',X_test.shape)\n",
        "print('y_train size :',y_train.shape)\n",
        "print('y_test size :',y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaled_df = scaler.fit_transform(X_train)\n",
        "scaled_df = pd.DataFrame(scaled_df, columns=X_train.columns)\n",
        "\n",
        "#**Now we can see that the values of all independent variables lie in a comparable range**\n",
        "#**Now our data is ready to fit into regression model**\n",
        "\n",
        "# defining a function for regression model\n",
        "\n",
        "# building and training the model with train data, using sklearn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "print(f'R^2 score for Train using sklearn: {lin_reg.score(X_train, y_train)}')\n",
        "print(f'R^2 score for Test using sklearn: {lin_reg.score(X_test, y_test)}')\n",
        "\n",
        "y_pred_train = lin_reg.predict(X_train)\n",
        "y_pred_test = lin_reg.predict(X_test)\n",
        "\n",
        "print(\"\\nMean Absolute Error for Train:\", metrics.mean_absolute_error(y_pred_train,y_train))\n",
        "print(\"Mean Absolute Error for Test:\", metrics.mean_absolute_error(y_pred_test,y_test))\n",
        "#mean_absolute_percentage_error\n",
        "print(\"\\nMean Absolute Percentage Error for Train:\", metrics.mean_absolute_percentage_error(y_pred_train,y_train))\n",
        "print(\"Mean Absolute Percentage Error for Test:\", metrics.mean_absolute_percentage_error(y_pred_test,y_test))\n",
        "\n",
        "\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "regr = MLPRegressor(random_state=1, max_iter=500).fit(X_train, y_train)\n",
        "print(f'R^2 score for Train using mlp: {regr.score(X_train, y_train)}')\n",
        "print(f'R^2 score for Test using mlp: {regr.score(X_test, y_test)}')\n",
        "\n",
        "y_pred_train = regr.predict(X_train)\n",
        "y_pred_test = regr.predict(X_test)\n",
        "\n",
        "print(\"\\nMean Absolute Error for Train:\", metrics.mean_absolute_error(y_pred_train,y_train))\n",
        "print(\"Mean Absolute Error for Test:\", metrics.mean_absolute_error(y_pred_test,y_test))\n",
        "\n",
        "#mean_absolute_percentage_error\n",
        "print(\"\\nMean Absolute Percentage Error for Train:\", metrics.mean_absolute_percentage_error(y_pred_train,y_train))\n",
        "print(\"Mean Absolute Percentage Error for Test:\", metrics.mean_absolute_percentage_error(y_pred_test,y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `**여기서부터 코드 추가함!**`\n"
      ],
      "metadata": {
        "id": "MhYXmfWNcXLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(regr.activation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IXtbBZRSnAi",
        "outputId": "ee081df8-c609-4b31-a740-08f6757ff48c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "relu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(regr.hidden_layer_sizes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUKQZX9sSm4Y",
        "outputId": "4655d037-07c9-4351-9303-636b3fc62d61"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#regr = MLPRegressor(random_state=1, max_iter=500).fit(X_train, y_train)\n",
        "regr = MLPRegressor(hidden_layer_sizes=(30, 30), random_state=1, max_iter=500).fit(X_train, y_train)\n",
        "\n",
        "print(f'R^2 score for Train using mlp: {regr.score(X_train, y_train)}')\n",
        "print(f'R^2 score for Test using mlp: {regr.score(X_test, y_test)}')\n",
        "\n",
        "y_pred_train = regr.predict(X_train)\n",
        "y_pred_test = regr.predict(X_test)\n",
        "\n",
        "print(\"\\nMean Absolute Error for Train:\", metrics.mean_absolute_error(y_pred_train,y_train))\n",
        "print(\"Mean Absolute Error for Test:\", metrics.mean_absolute_error(y_pred_test,y_test))\n",
        "\n",
        "#mean_absolute_percentage_error\n",
        "print(\"\\nMean Absolute Percentage Error for Train:\", metrics.mean_absolute_percentage_error(y_pred_train,y_train))\n",
        "print(\"Mean Absolute Percentage Error for Test:\", metrics.mean_absolute_percentage_error(y_pred_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k30fOLIcTed5",
        "outputId": "d7d39031-2215-4c39-b695-7b6fe8ab67d4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 score for Train using mlp: 0.9671328826764903\n",
            "R^2 score for Test using mlp: 0.9662762412009225\n",
            "\n",
            "Mean Absolute Error for Train: 420.3274165154688\n",
            "Mean Absolute Error for Test: 415.10111348499595\n",
            "\n",
            "Mean Absolute Percentage Error for Train: 0.23232682845088745\n",
            "Mean Absolute Percentage Error for Test: 0.1303447983884328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "activation_functions = ['identity', 'logistic', 'tanh', 'relu']\n",
        "\n",
        "for activation in activation_functions:\n",
        "    regr = MLPRegressor(activation=activation, hidden_layer_sizes=(30, 30), random_state=1, max_iter=500)\n",
        "    regr.fit(X_train, y_train)\n",
        "\n",
        "    # 훈련 및 테스트 데이터에 대한 R^2 점수 출력\n",
        "    print(f'Activation function: {activation}')\n",
        "    print(f'R^2 score for Train: {regr.score(X_train, y_train)}')\n",
        "    print(f'R^2 score for Test: {regr.score(X_test, y_test)}')\n",
        "\n",
        "    # 예측값 생성\n",
        "    y_pred_train = regr.predict(X_train)\n",
        "    y_pred_test = regr.predict(X_test)\n",
        "\n",
        "    # 평균 절대 오차 계산 및 출력\n",
        "    print(\"Mean Absolute Error for Train:\", metrics.mean_absolute_error(y_pred_train, y_train))\n",
        "    print(\"Mean Absolute Error for Test:\", metrics.mean_absolute_error(y_pred_test, y_test))\n",
        "\n",
        "    # 평균 절대 퍼센트 오차 계산 및 출력\n",
        "    print(\"Mean Absolute Percentage Error for Train:\", metrics.mean_absolute_percentage_error(y_pred_train, y_train))\n",
        "    print(\"Mean Absolute Percentage Error for Test:\", metrics.mean_absolute_percentage_error(y_pred_test, y_test))\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCaIyMtjTebt",
        "outputId": "b0158a91-4c54-4bd4-9e64-3a150fa11a0d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation function: identity\n",
            "R^2 score for Train: 0.8808786308579264\n",
            "R^2 score for Test: 0.8840125146946172\n",
            "Mean Absolute Error for Train: 899.8640869710366\n",
            "Mean Absolute Error for Test: 883.0591672262307\n",
            "Mean Absolute Percentage Error for Train: 1.9119232194782667\n",
            "Mean Absolute Percentage Error for Test: 1.4449581788431218\n",
            "--------------------------------------------------\n",
            "Activation function: logistic\n",
            "R^2 score for Train: -0.08079508434332672\n",
            "R^2 score for Test: -0.07832414199716031\n",
            "Mean Absolute Error for Train: 2850.1039540373895\n",
            "Mean Absolute Error for Test: 2767.1391638278164\n",
            "Mean Absolute Percentage Error for Train: 1.0164146607763744\n",
            "Mean Absolute Percentage Error for Test: 0.9868274490615908\n",
            "--------------------------------------------------\n",
            "Activation function: tanh\n",
            "R^2 score for Train: -0.0715528956533038\n",
            "R^2 score for Test: -0.06899593709595186\n",
            "Mean Absolute Error for Train: 2856.5404414492286\n",
            "Mean Absolute Error for Test: 2773.118496479584\n",
            "Mean Absolute Percentage Error for Train: 0.9948190568569976\n",
            "Mean Absolute Percentage Error for Test: 0.9657665220454212\n",
            "--------------------------------------------------\n",
            "Activation function: relu\n",
            "R^2 score for Train: 0.9487190094552123\n",
            "R^2 score for Test: 0.9483035717937991\n",
            "Mean Absolute Error for Train: 543.7857346955213\n",
            "Mean Absolute Error for Test: 535.0554923423435\n",
            "Mean Absolute Percentage Error for Train: 0.7549441804282211\n",
            "Mean Absolute Percentage Error for Test: 0.42331882370730334\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into log(dependent) and independent variables\n",
        "# 데이터 디렉토리 경로 설정\n",
        "\n",
        "X = diamonds.drop('price', axis=1)\n",
        "y=diamonds['price']\n",
        "y=y.transform(lambda X: np.log(X))\n",
        "\n",
        "le = LabelEncoder()\n",
        "diamonds['cut'] = le.fit_transform(diamonds['cut'])\n",
        "diamonds['color'] = le.fit_transform(diamonds['color'])\n",
        "diamonds['clarity'] = le.fit_transform(diamonds['clarity'])\n",
        "diamonds.dtypes\n",
        "#**Splitting the data into train and test**\n",
        "# Splitting the data into dependent and independent variables\n",
        "X=diamonds.drop('price', axis=1)\n",
        "y=diamonds['price']\n",
        "\n",
        "# Splitting into test and train data (70:30)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.30, random_state = 1)\n",
        "print('X_train size :',X_train.shape)\n",
        "print('X_test size :',X_test.shape)\n",
        "print('y_train size :',y_train.shape)\n",
        "print('y_test size :',y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5oPsoSnaSwH",
        "outputId": "a76f244a-4a07-463a-dd81-b3913f872ea4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train size : (37758, 10)\n",
            "X_test size : (16182, 10)\n",
            "y_train size : (37758,)\n",
            "y_test size : (16182,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O5J45FQAbXOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pNLujw6pbX4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#regr = MLPRegressor(random_state=1, max_iter=500).fit(X_train, y_train)\n",
        "regr = MLPRegressor(hidden_layer_sizes=(30, 30), random_state=1, max_iter=500).fit(X_train, y_train)\n",
        "\n",
        "print(f'R^2 score for Train using mlp: {regr.score(X_train, y_train)}')\n",
        "print(f'R^2 score for Test using mlp: {regr.score(X_test, y_test)}')\n",
        "\n",
        "y_pred_train = regr.predict(X_train)\n",
        "y_pred_test = regr.predict(X_test)\n",
        "\n",
        "print(\"\\nMean Absolute Error for Train:\", metrics.mean_absolute_error(y_pred_train,y_train))\n",
        "print(\"Mean Absolute Error for Test:\", metrics.mean_absolute_error(y_pred_test,y_test))\n",
        "\n",
        "#mean_absolute_percentage_error\n",
        "print(\"\\nMean Absolute Percentage Error for Train:\", metrics.mean_absolute_percentage_error(y_pred_train,y_train))\n",
        "print(\"Mean Absolute Percentage Error for Test:\", metrics.mean_absolute_percentage_error(y_pred_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYAEQEGLa2lU",
        "outputId": "e0703c5f-4a1d-486e-e7f6-de423550a765"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 score for Train using mlp: 0.9773193107057263\n",
            "R^2 score for Test using mlp: 0.9815736168578064\n",
            "\n",
            "Mean Absolute Error for Train: 346.6129986801313\n",
            "Mean Absolute Error for Test: 334.43609451645074\n",
            "\n",
            "Mean Absolute Percentage Error for Train: 0.1769091385353018\n",
            "Mean Absolute Percentage Error for Test: 0.37593207241486687\n"
          ]
        }
      ]
    }
  ]
}