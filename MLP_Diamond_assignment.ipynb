{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t6YQPHhXjJg_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2369c7c-cbc5-4764-9bd1-bcd89f632a91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "   Unnamed: 0  carat      cut color clarity  depth  table  price     x     y  \\\n",
            "0           1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98   \n",
            "1           2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84   \n",
            "\n",
            "      z  \n",
            "0  2.43  \n",
            "1  2.31  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 53940 entries, 0 to 53939\n",
            "Data columns (total 10 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   carat    53940 non-null  float64\n",
            " 1   cut      53940 non-null  object \n",
            " 2   color    53940 non-null  object \n",
            " 3   clarity  53940 non-null  object \n",
            " 4   depth    53940 non-null  float64\n",
            " 5   table    53940 non-null  float64\n",
            " 6   price    53940 non-null  int64  \n",
            " 7   x        53940 non-null  float64\n",
            " 8   y        53940 non-null  float64\n",
            " 9   z        53940 non-null  float64\n",
            "dtypes: float64(6), int64(1), object(3)\n",
            "memory usage: 4.1+ MB\n",
            "carat\n",
            "0.30    2604\n",
            "0.31    2249\n",
            "1.01    2242\n",
            "0.70    1981\n",
            "0.32    1840\n",
            "        ... \n",
            "3.02       1\n",
            "3.65       1\n",
            "3.50       1\n",
            "3.22       1\n",
            "3.11       1\n",
            "Name: count, Length: 273, dtype: int64\n",
            "cut\n",
            "Ideal        21551\n",
            "Premium      13791\n",
            "Very Good    12082\n",
            "Good          4906\n",
            "Fair          1610\n",
            "Name: count, dtype: int64\n",
            "color\n",
            "G    11292\n",
            "E     9797\n",
            "F     9542\n",
            "H     8304\n",
            "D     6775\n",
            "I     5422\n",
            "J     2808\n",
            "Name: count, dtype: int64\n",
            "clarity\n",
            "SI1     13065\n",
            "VS2     12258\n",
            "SI2      9194\n",
            "VS1      8171\n",
            "VVS2     5066\n",
            "VVS1     3655\n",
            "IF       1790\n",
            "I1        741\n",
            "Name: count, dtype: int64\n",
            "depth\n",
            "62.0    2239\n",
            "61.9    2163\n",
            "61.8    2077\n",
            "62.2    2039\n",
            "62.1    2020\n",
            "        ... \n",
            "71.3       1\n",
            "44.0       1\n",
            "53.0       1\n",
            "53.1       1\n",
            "54.7       1\n",
            "Name: count, Length: 184, dtype: int64\n",
            "table\n",
            "56.0    9881\n",
            "57.0    9724\n",
            "58.0    8369\n",
            "59.0    6572\n",
            "55.0    6268\n",
            "        ... \n",
            "51.6       1\n",
            "63.5       1\n",
            "43.0       1\n",
            "62.4       1\n",
            "61.6       1\n",
            "Name: count, Length: 127, dtype: int64\n",
            "price\n",
            "605      132\n",
            "802      127\n",
            "625      126\n",
            "828      125\n",
            "776      124\n",
            "        ... \n",
            "8816       1\n",
            "14704      1\n",
            "14699      1\n",
            "14698      1\n",
            "9793       1\n",
            "Name: count, Length: 11602, dtype: int64\n",
            "x\n",
            "4.37     448\n",
            "4.34     437\n",
            "4.33     429\n",
            "4.38     428\n",
            "4.32     425\n",
            "        ... \n",
            "10.74      1\n",
            "9.36       1\n",
            "8.89       1\n",
            "10.23      1\n",
            "10.00      1\n",
            "Name: count, Length: 554, dtype: int64\n",
            "y\n",
            "4.34     437\n",
            "4.37     435\n",
            "4.35     425\n",
            "4.33     421\n",
            "4.32     414\n",
            "        ... \n",
            "8.89       1\n",
            "10.16      1\n",
            "9.46       1\n",
            "9.63       1\n",
            "31.80      1\n",
            "Name: count, Length: 552, dtype: int64\n",
            "z\n",
            "2.70     767\n",
            "2.69     748\n",
            "2.71     738\n",
            "2.68     730\n",
            "2.72     697\n",
            "        ... \n",
            "5.79       1\n",
            "5.72       1\n",
            "5.91       1\n",
            "5.61       1\n",
            "31.80      1\n",
            "Name: count, Length: 375, dtype: int64\n",
            "X_train size : (37758, 9)\n",
            "X_test size : (16182, 9)\n",
            "y_train size : (37758,)\n",
            "y_test size : (16182,)\n",
            "R^2 score for Train using sklearn: 0.8838780842365068\n",
            "R^2 score for Test using sklearn: 0.8878187588744918\n",
            "\n",
            "Mean Absolute Error for Train: 872.0510348697445\n",
            "Mean Absolute Error for Test: 853.7910819184326\n",
            "\n",
            "Mean Absolute Percentage Error for Train: 1.5814641367500504\n",
            "Mean Absolute Percentage Error for Test: 1.4816394864517115\n"
          ]
        }
      ],
      "source": [
        "### Context\n",
        "#This classic dataset contains the prices and other attributes of almost 54,000 diamonds.\n",
        "\n",
        "### Content\n",
        "'''\n",
        "**price** price in US dollars (\\\\$326--\\\\$18,823)\n",
        "\n",
        "**carat** weight of the diamond (0.2--5.01)\n",
        "\n",
        "**cut** quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n",
        "\n",
        "**color** diamond colour, from J (worst) to D (best)\n",
        "\n",
        "**clarity** a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n",
        "\n",
        "**x** length in mm (0--10.74)\n",
        "\n",
        "**y** width in mm (0--58.9)\n",
        "\n",
        "**z** depth in mm (0--31.8)\n",
        "\n",
        "**depth** total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43--79)\n",
        "\n",
        "**table** width of top of diamond relative to widest point (43--95)\n",
        "'''\n",
        "\n",
        "# importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# loding the csv file as pandas dataframe\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 데이터 디렉토리 경로 설정\n",
        "data_dir = '/content/diamonds.csv'\n",
        "\n",
        "diamonds = pd.read_csv(data_dir)\n",
        "# Looking at the loaded data\n",
        "print(diamonds.head(2))\n",
        "\n",
        "# dropping the first column\n",
        "diamonds = diamonds.drop(diamonds.columns[0], axis=1)\n",
        "\n",
        "# code to directly delete first column, while loding the data from csv file\n",
        "# diamonds = pd.read_csv('G:\\My Research\\CSV Files\\diamonds.csv').iloc[:,1:]\n",
        "diamonds.head()\n",
        "# checking the datatypes and null values in the data\n",
        "diamonds.info()\n",
        "#**From the above, we can see that there are no null values in our dataset.**\n",
        "# if there are null values presents in the data, then we can use imputer for filling those null values\n",
        "# from sklearn.preprocessing import Imputer\n",
        "# checking for the unique values and their total counts in the dataset,\n",
        "# to get an insight about categorical and numerical variables in the dataset\n",
        "for i in diamonds:\n",
        "    print(diamonds[i].value_counts())\n",
        "\n",
        "# defining the variables into Categorical and Numerical\n",
        "#**Categorical Variables :** cut, color, clarity\n",
        "#*Numerical Variables :** carat, depth, table, price, x, y, z\n",
        "# defining the variables into Dependent and Independent\n",
        "#**Dependent Variable :** price\n",
        "#**Independent Variable :** carat, cut, color, clarity, depth, table, x, y, z\n",
        "# Now we will see the distribution of variables\n",
        "d_cat = diamonds[['cut', 'color', 'clarity']]\n",
        "d_num = diamonds[['carat', 'depth', 'table', 'price', 'x', 'y', 'z']]\n",
        "d_num.describe()\n",
        "#From the above graph we can see that there are many outliers present in our data, thus outlier treatment is necessary,\n",
        "#but here, the target variable is Price and as we are predicting price of diamonds, then extreme values are possible, depending about the dimentions of the diamonds.\n",
        "diamonds.price.describe()\n",
        "\n",
        "# encoding categorical variables using LabelEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "diamonds['cut'] = le.fit_transform(diamonds['cut'])\n",
        "diamonds['color'] = le.fit_transform(diamonds['color'])\n",
        "diamonds['clarity'] = le.fit_transform(diamonds['clarity'])\n",
        "diamonds.dtypes\n",
        "#**Splitting the data into train and test**\n",
        "# Splitting the data into dependent and independent variables\n",
        "X=diamonds.drop('price', axis=1)\n",
        "y=diamonds['price']\n",
        "\n",
        "# Splitting into test and train data (70:30)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.30, random_state = 1)\n",
        "print('X_train size :',X_train.shape)\n",
        "print('X_test size :',X_test.shape)\n",
        "print('y_train size :',y_train.shape)\n",
        "print('y_test size :',y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaled_df = scaler.fit_transform(X_train)\n",
        "scaled_df = pd.DataFrame(scaled_df, columns=X_train.columns)\n",
        "\n",
        "#**Now we can see that the values of all independent variables lie in a comparable range**\n",
        "#**Now our data is ready to fit into regression model**\n",
        "\n",
        "# defining a function for regression model\n",
        "\n",
        "# building and training the model with train data, using sklearn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "print(f'R^2 score for Train using sklearn: {lin_reg.score(X_train, y_train)}')\n",
        "print(f'R^2 score for Test using sklearn: {lin_reg.score(X_test, y_test)}')\n",
        "\n",
        "y_pred_train = lin_reg.predict(X_train)\n",
        "y_pred_test = lin_reg.predict(X_test)\n",
        "\n",
        "print(\"\\nMean Absolute Error for Train:\", metrics.mean_absolute_error(y_pred_train,y_train))\n",
        "print(\"Mean Absolute Error for Test:\", metrics.mean_absolute_error(y_pred_test,y_test))\n",
        "#mean_absolute_percentage_error\n",
        "print(\"\\nMean Absolute Percentage Error for Train:\", metrics.mean_absolute_percentage_error(y_pred_train,y_train))\n",
        "print(\"Mean Absolute Percentage Error for Test:\", metrics.mean_absolute_percentage_error(y_pred_test,y_test))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `**여기서부터 코드 추가함!**`\n"
      ],
      "metadata": {
        "id": "MhYXmfWNcXLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "regr = MLPRegressor(hidden_layer_sizes=(50, 30), random_state=1, max_iter=500).fit(X_train, y_train)\n",
        "\n",
        "print(f'R^2 score for Train using mlp: {regr.score(X_train, y_train)}')\n",
        "print(f'R^2 score for Test using mlp: {regr.score(X_test, y_test)}')\n",
        "\n",
        "y_pred_train = regr.predict(X_train)\n",
        "y_pred_test = regr.predict(X_test)\n",
        "\n",
        "print(\"\\nMean Absolute Error for Train:\", metrics.mean_absolute_error(y_pred_train,y_train))\n",
        "print(\"Mean Absolute Error for Test:\", metrics.mean_absolute_error(y_pred_test,y_test))\n",
        "\n",
        "#mean_absolute_percentage_error\n",
        "print(\"\\nMean Absolute Percentage Error for Train:\", metrics.mean_absolute_percentage_error(y_pred_train,y_train))\n",
        "print(\"Mean Absolute Percentage Error for Test:\", metrics.mean_absolute_percentage_error(y_pred_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k30fOLIcTed5",
        "outputId": "55d79048-349e-4fc2-aa27-29ea0722bf85"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 score for Train using mlp: 0.9671328826764903\n",
            "R^2 score for Test using mlp: 0.9662762412009225\n",
            "\n",
            "Mean Absolute Error for Train: 420.3274165154688\n",
            "Mean Absolute Error for Test: 415.10111348499595\n",
            "\n",
            "Mean Absolute Percentage Error for Train: 0.23232682845088745\n",
            "Mean Absolute Percentage Error for Test: 0.1303447983884328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "activation_functions = ['identity', 'logistic', 'tanh', 'relu']\n",
        "\n",
        "for activation in activation_functions:\n",
        "    regr = MLPRegressor(activation=activation, hidden_layer_sizes=(30, 30), random_state=1, max_iter=500).fit(X_train, y_train)\n",
        "\n",
        "    # 훈련 및 테스트 데이터에 대한 R^2 점수 출력\n",
        "    print(f'Activation function: {activation}')\n",
        "    print(f'R^2 score for Train: {regr.score(X_train, y_train)}')\n",
        "    print(f'R^2 score for Test: {regr.score(X_test, y_test)}')\n",
        "\n",
        "    # 예측값 생성\n",
        "    y_pred_train = regr.predict(X_train)\n",
        "    y_pred_test = regr.predict(X_test)\n",
        "\n",
        "    # 평균 절대 오차 계산 및 출력\n",
        "    print(\"Mean Absolute Error for Train:\", metrics.mean_absolute_error(y_pred_train, y_train))\n",
        "    print(\"Mean Absolute Error for Test:\", metrics.mean_absolute_error(y_pred_test, y_test))\n",
        "\n",
        "    # 평균 절대 퍼센트 오차 계산 및 출력\n",
        "    print(\"Mean Absolute Percentage Error for Train:\", metrics.mean_absolute_percentage_error(y_pred_train, y_train))\n",
        "    print(\"Mean Absolute Percentage Error for Test:\", metrics.mean_absolute_percentage_error(y_pred_test, y_test))\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCaIyMtjTebt",
        "outputId": "fbcf22f9-7769-4635-c84f-960770ef41ed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation function: identity\n",
            "R^2 score for Train: 0.8808786308579264\n",
            "R^2 score for Test: 0.8840125146946172\n",
            "Mean Absolute Error for Train: 899.8640869710366\n",
            "Mean Absolute Error for Test: 883.0591672262307\n",
            "Mean Absolute Percentage Error for Train: 1.9119232194782667\n",
            "Mean Absolute Percentage Error for Test: 1.4449581788431218\n",
            "--------------------------------------------------\n",
            "Activation function: logistic\n",
            "R^2 score for Train: -0.08079508434332672\n",
            "R^2 score for Test: -0.07832414199716031\n",
            "Mean Absolute Error for Train: 2850.1039540373895\n",
            "Mean Absolute Error for Test: 2767.1391638278164\n",
            "Mean Absolute Percentage Error for Train: 1.0164146607763744\n",
            "Mean Absolute Percentage Error for Test: 0.9868274490615908\n",
            "--------------------------------------------------\n",
            "Activation function: tanh\n",
            "R^2 score for Train: -0.0715528956533038\n",
            "R^2 score for Test: -0.06899593709595186\n",
            "Mean Absolute Error for Train: 2856.5404414492286\n",
            "Mean Absolute Error for Test: 2773.118496479584\n",
            "Mean Absolute Percentage Error for Train: 0.9948190568569976\n",
            "Mean Absolute Percentage Error for Test: 0.9657665220454212\n",
            "--------------------------------------------------\n",
            "Activation function: relu\n",
            "R^2 score for Train: 0.9487190094552123\n",
            "R^2 score for Test: 0.9483035717937991\n",
            "Mean Absolute Error for Train: 543.7857346955213\n",
            "Mean Absolute Error for Test: 535.0554923423435\n",
            "Mean Absolute Percentage Error for Train: 0.7549441804282211\n",
            "Mean Absolute Percentage Error for Test: 0.42331882370730334\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**전처리**\n",
        "1. 종속변수 로그화\n",
        "2. 범주형 변수 one-hot encoding\n",
        "3. min-max 스케일링 수행\n",
        "4. train data 70%, test data 30%"
      ],
      "metadata": {
        "id": "Y-DAJWxjqwre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into log(dependent) and independent variables\n",
        "data_dir = '/content/diamonds.csv'\n",
        "\n",
        "diamonds = pd.read_csv(data_dir)\n",
        "# 첫번째 열 삭제\n",
        "diamonds = diamonds.drop(diamonds.columns[0], axis=1)\n",
        "\n",
        "# 종속변수 로그화\n",
        "X = diamonds.drop('price', axis=1)\n",
        "y=diamonds['price']\n",
        "y=y.transform(lambda X: np.log(X))\n",
        "\n",
        "# 범주형 변수 one-hot encoding\n",
        "le = LabelEncoder()\n",
        "X['cut'] = le.fit_transform(X['cut'])\n",
        "X['color'] = le.fit_transform(X['color'])\n",
        "X['clarity'] = le.fit_transform(X['clarity'])\n",
        "X.dtypes\n",
        "\n",
        "# MinMaxScaling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "# Splitting into test and train data (70:30)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled_df,y, test_size = 0.30, random_state = 1)\n",
        "print('X_train size :',X_train.shape)\n",
        "print('X_test size :',X_test.shape)\n",
        "print('y_train size :',y_train.shape)\n",
        "print('y_test size :',y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5oPsoSnaSwH",
        "outputId": "94f4c9fb-2a70-410f-dc52-015de73a68c6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train size : (37758, 9)\n",
            "X_test size : (16182, 9)\n",
            "y_train size : (37758,)\n",
            "y_test size : (16182,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리 확인"
      ],
      "metadata": {
        "id": "h623R_p6rctr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.head(3))\n",
        "print(y_train.head(3))\n",
        "print(X_test.head(3))\n",
        "print(y_test.head(3))\n"
      ],
      "metadata": {
        "id": "O5J45FQAbXOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f51f5baf-15e7-4ffb-87d3-e0b7c10ba5b6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          carat   cut     color   clarity     depth     table         x  \\\n",
            "30083  0.024948  0.50  0.833333  1.000000  0.513889  0.250000  0.411546   \n",
            "21864  0.278586  0.75  0.333333  0.285714  0.550000  0.288462  0.684358   \n",
            "3761   0.106029  0.50  0.333333  0.571429  0.530556  0.250000  0.529795   \n",
            "\n",
            "              y         z  \n",
            "30083  0.074703  0.085220  \n",
            "21864  0.124278  0.144969  \n",
            "3761   0.097623  0.111635  \n",
            "30083    6.579251\n",
            "21864    9.202913\n",
            "3761     8.148156\n",
            "Name: price, dtype: float64\n",
            "          carat  cut     color   clarity     depth     table         x  \\\n",
            "2714   0.027027  0.5  0.666667  0.285714  0.519444  0.230769  0.412477   \n",
            "14653  0.207900  0.5  0.833333  0.714286  0.530556  0.269231  0.631285   \n",
            "52760  0.087318  0.5  0.000000  0.571429  0.500000  0.269231  0.513035   \n",
            "\n",
            "              y         z  \n",
            "2714   0.075722  0.086164  \n",
            "14653  0.113922  0.131761  \n",
            "52760  0.094058  0.105975  \n",
            "2714     6.335054\n",
            "14653    8.685078\n",
            "52760    7.848543\n",
            "Name: price, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP 성능 확인\n",
        "1. RELU 함수 사용\n",
        " - identity, logistic, tanh 활성화 함수는 성능이 좋지 않아 사용하지 않음.\n",
        "2. 2개의 Hidden layer를 가지는 MLP 구현\n",
        "3. 레이어별 30개의 노드 사용\n"
      ],
      "metadata": {
        "id": "vhlU1fq6sIN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "#regr = MLPRegressor(random_state=1, max_iter=500).fit(X_train, y_train)\n",
        "regr = MLPRegressor(hidden_layer_sizes=(30, 30), random_state=1, max_iter=500).fit(X_train, y_train)\n",
        "\n",
        "print(f'R^2 score for Train using mlp: {regr.score(X_train, y_train)}')\n",
        "print(f'R^2 score for Test using mlp: {regr.score(X_test, y_test)}')\n",
        "\n",
        "y_pred_train = regr.predict(X_train)\n",
        "y_pred_test = regr.predict(X_test)\n",
        "\n",
        "print(\"\\nMean Absolute Error for Train:\", metrics.mean_absolute_error(y_pred_train,y_train))\n",
        "print(\"Mean Absolute Error for Test:\", metrics.mean_absolute_error(y_pred_test,y_test))\n",
        "\n",
        "#mean_absolute_percentage_error\n",
        "print(\"\\nMean Absolute Percentage Error for Train:\", metrics.mean_absolute_percentage_error(y_pred_train,y_train))\n",
        "print(\"Mean Absolute Percentage Error for Test:\", metrics.mean_absolute_percentage_error(y_pred_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYAEQEGLa2lU",
        "outputId": "d2cc9fd6-d47f-48a4-af4a-31704241957d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 score for Train using mlp: 0.98144072090662\n",
            "R^2 score for Test using mlp: 0.9814190555358763\n",
            "\n",
            "Mean Absolute Error for Train: 0.1082256129585938\n",
            "Mean Absolute Error for Test: 0.10804466294591734\n",
            "\n",
            "Mean Absolute Percentage Error for Train: 0.014321371333498784\n",
            "Mean Absolute Percentage Error for Test: 0.01427617259648974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "사용된 하이퍼 파라미터"
      ],
      "metadata": {
        "id": "PNvOq6oltYbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hidden layer sizes:\", regr.hidden_layer_sizes)\n",
        "print(\"Activation function:\", regr.activation)\n",
        "print(\"Solver:\", regr.solver)\n",
        "print(\"Alpha (L2 regularization strength):\", regr.alpha)\n",
        "print(\"Learning rate schedule:\", regr.learning_rate)\n",
        "print(\"Maximum number of iterations:\", regr.max_iter)\n",
        "print(\"Random state:\", regr.random_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75pxNGQVtUBd",
        "outputId": "6c260af1-af8c-49fe-ddd9-47f0580a864f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden layer sizes: (30, 30)\n",
            "Activation function: relu\n",
            "Solver: adam\n",
            "Alpha (L2 regularization strength): 0.0001\n",
            "Learning rate schedule: constant\n",
            "Maximum number of iterations: 500\n",
            "Random state: 1\n"
          ]
        }
      ]
    }
  ]
}